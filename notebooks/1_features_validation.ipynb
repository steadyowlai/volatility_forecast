{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6bf7fa",
   "metadata": {},
   "source": [
    "# Feature Validation - Level 1\n",
    "\n",
    "This notebook validates the Level 1 features generated by the features service.\n",
    "\n",
    "**Objectives:**\n",
    "1. Load and inspect feature data\n",
    "2. Check for missing values and their patterns\n",
    "3. Visualize key features over time\n",
    "4. Verify no lookahead bias\n",
    "5. Check feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Project root detection\n",
    "project_root = Path.cwd()\n",
    "while project_root.name != 'volatility_forecast' and project_root.parent != project_root:\n",
    "    project_root = project_root.parent\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ac38a",
   "metadata": {},
   "source": [
    "## 1. Load Features Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all feature partitions\n",
    "features_path = project_root / \"data/features.L1\"\n",
    "feature_files = sorted(list(features_path.glob(\"date=*/features.parquet\")))\n",
    "\n",
    "print(f\"Found {len(feature_files)} feature partitions\")\n",
    "\n",
    "features_df = pd.concat([pd.read_parquet(f) for f in feature_files], ignore_index=True)\n",
    "features_df['date'] = pd.to_datetime(features_df['date'])\n",
    "features_df = features_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nShape: {features_df.shape}\")\n",
    "print(f\"Date range: {features_df['date'].min().date()} to {features_df['date'].max().date()}\")\n",
    "print(f\"\\nColumns ({len(features_df.columns)}):\")\n",
    "print(features_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c9b9636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>spy_ret_1d</th>\n",
       "      <th>spy_ret_5d</th>\n",
       "      <th>spy_ret_10d</th>\n",
       "      <th>spy_ret_20d</th>\n",
       "      <th>spy_ret_60d</th>\n",
       "      <th>spy_vol_5d</th>\n",
       "      <th>spy_vol_10d</th>\n",
       "      <th>spy_vol_20d</th>\n",
       "      <th>spy_vol_60d</th>\n",
       "      <th>...</th>\n",
       "      <th>vix</th>\n",
       "      <th>vix3m</th>\n",
       "      <th>vix_term</th>\n",
       "      <th>rsi_spy_14</th>\n",
       "      <th>corr_spy_tlt_20d</th>\n",
       "      <th>corr_spy_hyg_20d</th>\n",
       "      <th>corr_spy_tlt_60d</th>\n",
       "      <th>corr_spy_hyg_60d</th>\n",
       "      <th>hyg_tlt_spread</th>\n",
       "      <th>rv_vix_spread_20d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>1.140653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-19</td>\n",
       "      <td>-0.000863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.990000</td>\n",
       "      <td>19.639999</td>\n",
       "      <td>1.155974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-20</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.470000</td>\n",
       "      <td>18.940001</td>\n",
       "      <td>1.224305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>18.629999</td>\n",
       "      <td>1.192702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-24</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.930000</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>1.174513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-11-25</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.190000</td>\n",
       "      <td>18.190001</td>\n",
       "      <td>1.197498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001232</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-11-27</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.120000</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>1.147487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>-0.002967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.129999</td>\n",
       "      <td>18.490000</td>\n",
       "      <td>1.146311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>14.670000</td>\n",
       "      <td>17.580000</td>\n",
       "      <td>1.198364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006393</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-12-02</td>\n",
       "      <td>-0.010257</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.910000</td>\n",
       "      <td>18.330000</td>\n",
       "      <td>1.152106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  spy_ret_1d  spy_ret_5d  spy_ret_10d  spy_ret_20d  spy_ret_60d   \n",
       "0 2015-11-18         NaN         NaN          NaN          NaN          NaN  \\\n",
       "1 2015-11-19   -0.000863         NaN          NaN          NaN          NaN   \n",
       "2 2015-11-20    0.003638         NaN          NaN          NaN          NaN   \n",
       "3 2015-11-23   -0.001147         NaN          NaN          NaN          NaN   \n",
       "4 2015-11-24    0.001338         NaN          NaN          NaN          NaN   \n",
       "5 2015-11-25   -0.000143    0.002823          NaN          NaN          NaN   \n",
       "6 2015-11-27    0.001146    0.004831          NaN          NaN          NaN   \n",
       "7 2015-11-30   -0.004160   -0.002967          NaN          NaN          NaN   \n",
       "8 2015-12-01    0.009490    0.007671          NaN          NaN          NaN   \n",
       "9 2015-12-02   -0.010257   -0.003925          NaN          NaN          NaN   \n",
       "\n",
       "   spy_vol_5d  spy_vol_10d  spy_vol_20d  spy_vol_60d  ...        vix   \n",
       "0         NaN          NaN          NaN          NaN  ...  16.850000  \\\n",
       "1         NaN          NaN          NaN          NaN  ...  16.990000   \n",
       "2         NaN          NaN          NaN          NaN  ...  15.470000   \n",
       "3         NaN          NaN          NaN          NaN  ...  15.620000   \n",
       "4         NaN          NaN          NaN          NaN  ...  15.930000   \n",
       "5         NaN          NaN          NaN          NaN  ...  15.190000   \n",
       "6         NaN          NaN          NaN          NaN  ...  15.120000   \n",
       "7         NaN          NaN          NaN          NaN  ...  16.129999   \n",
       "8    0.010549          NaN          NaN          NaN  ...  14.670000   \n",
       "9    0.014616          NaN          NaN          NaN  ...  15.910000   \n",
       "\n",
       "       vix3m  vix_term  rsi_spy_14  corr_spy_tlt_20d  corr_spy_hyg_20d   \n",
       "0  19.219999  1.140653         NaN               NaN               NaN  \\\n",
       "1  19.639999  1.155974         NaN               NaN               NaN   \n",
       "2  18.940001  1.224305         NaN               NaN               NaN   \n",
       "3  18.629999  1.192702         NaN               NaN               NaN   \n",
       "4  18.709999  1.174513         NaN               NaN               NaN   \n",
       "5  18.190001  1.197498         NaN               NaN               NaN   \n",
       "6  17.350000  1.147487         NaN               NaN               NaN   \n",
       "7  18.490000  1.146311         NaN               NaN               NaN   \n",
       "8  17.580000  1.198364         NaN               NaN               NaN   \n",
       "9  18.330000  1.152106         NaN               NaN               NaN   \n",
       "\n",
       "   corr_spy_tlt_60d  corr_spy_hyg_60d  hyg_tlt_spread  rv_vix_spread_20d  \n",
       "0               NaN               NaN             NaN                NaN  \n",
       "1               NaN               NaN       -0.015636                NaN  \n",
       "2               NaN               NaN        0.002822                NaN  \n",
       "3               NaN               NaN             NaN                NaN  \n",
       "4               NaN               NaN        0.001411                NaN  \n",
       "5               NaN               NaN       -0.001232                NaN  \n",
       "6               NaN               NaN        0.002558                NaN  \n",
       "7               NaN               NaN       -0.004569                NaN  \n",
       "8               NaN               NaN       -0.006393                NaN  \n",
       "9               NaN               NaN       -0.002368                NaN  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e451a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21fc95",
   "metadata": {},
   "source": [
    "## 2. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = features_df.isnull().sum()\n",
    "missing_pct = (missing / len(features_df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values Summary:\")\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a359134",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "missing_pattern = features_df.head(100).isnull()\n",
    "sns.heatmap(missing_pattern.T, cbar=False, cmap='RdYlGn_r', ax=ax)\n",
    "ax.set_xlabel('Row Index (First 100 days)')\n",
    "ax.set_ylabel('Features')\n",
    "ax.set_title('Missing Value Pattern (First 100 Days; expected due to rolling windows)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5cde21",
   "metadata": {},
   "source": [
    "## 3. Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b328fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spy_ret_1d/20d: log returns (price changes)\n",
    "# spy_vol_5d/20d: realized volatility (how much price moves)\n",
    "# vix: implied volatility index (market's expectation of future volatility)\n",
    "# vix_term: VIX3M/VIX ratio (term structure of volatility)\n",
    "# rsi_spy_14: relative strength index (overbought/oversold momentum indicator)\n",
    "# drawdown_60d: peak-to-trough decline (max loss from recent high)\n",
    "\n",
    "features_to_plot = [\n",
    "    'spy_ret_1d', 'spy_ret_20d', \n",
    "    'spy_vol_5d', 'spy_vol_20d',\n",
    "    'vix', 'vix_term',\n",
    "    'rsi_spy_14', 'drawdown_60d'\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(features_to_plot):\n",
    "    data = features_df[col].dropna()\n",
    "    axes[i].hist(data, bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].set_title(f'{col} Distribution')\n",
    "    axes[i].axvline(data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {data.mean():.4f}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5bd358",
   "metadata": {},
   "source": [
    "## 4. Time Series of Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPY returns over different time windows\n",
    "# Shows how returns smooth out over longer periods\n",
    "# 1d: daily noise, 5d: weekly trends, 20d: monthly moves\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "return_cols = ['spy_ret_1d', 'spy_ret_5d', 'spy_ret_20d']\n",
    "titles = ['1-Day Returns', '5-Day Returns', '20-Day Returns']\n",
    "\n",
    "for i, (col, title) in enumerate(zip(return_cols, titles)):\n",
    "    axes[i].plot(features_df['date'], features_df[col], linewidth=0.8, alpha=0.7)\n",
    "    axes[i].set_ylabel('Log Return')\n",
    "    axes[i].set_title(f'SPY {title}')\n",
    "    axes[i].axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "    axes[i].grid(alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1672029",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "vol_cols = ['spy_vol_5d', 'spy_vol_10d', 'spy_vol_20d', 'spy_vol_60d']\n",
    "for col in vol_cols:\n",
    "    ax.plot(features_df['date'], features_df[col], label=col, linewidth=1.5, alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Realized Volatility')\n",
    "ax.set_title('SPY Realized Volatility (Multiple Windows)')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3750e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIX term structure analysis\n",
    "# VIX: current implied volatility (spot)\n",
    "# VIX3M: 3-month forward implied volatility\n",
    "# Flat: VIX3M/VIX = 1.0 (no term structure)\n",
    "# Contango: VIX3M > VIX (normal market, future vol expected higher)\n",
    "# Backwardation: VIX3M < VIX (stress market, near term vol spike)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(features_df['date'], features_df['vix'], label='VIX', linewidth=1)\n",
    "axes[0].plot(features_df['date'], features_df['vix3m'], label='VIX3M', linewidth=1, alpha=0.7)\n",
    "axes[0].set_ylabel('VIX Level')\n",
    "axes[0].set_title('VIX and VIX3M')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(features_df['date'], features_df['vix_term'], linewidth=1, color='purple')\n",
    "axes[1].axhline(1.0, color='red', linestyle='--', linewidth=2, label='Flat (=1.0)')\n",
    "axes[1].fill_between(features_df['date'], 1.0, features_df['vix_term'], \n",
    "                      where=(features_df['vix_term'] > 1.0), alpha=0.3, color='green', label='Contango')\n",
    "axes[1].fill_between(features_df['date'], 1.0, features_df['vix_term'], \n",
    "                      where=(features_df['vix_term'] < 1.0), alpha=0.3, color='red', label='Backwardation')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('VIX3M / VIX')\n",
    "axes[1].set_title('VIX Term Structure')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7affea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSI (Relative Strength Index) momentum indicator\n",
    "# Measures if stock is overbought (>70) or oversold (<30)\n",
    "# High RSI: strong buying pressure, potential reversal down\n",
    "# Low RSI: strong selling pressure, potential reversal up\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(features_df['date'], features_df['rsi_spy_14'], linewidth=1)\n",
    "ax.axhline(70, color='red', linestyle='--', linewidth=1, label='Overbought (70)')\n",
    "ax.axhline(30, color='green', linestyle='--', linewidth=1, label='Oversold (30)')\n",
    "ax.fill_between(features_df['date'], 70, 100, alpha=0.2, color='red')\n",
    "ax.fill_between(features_df['date'], 0, 30, alpha=0.2, color='green')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('RSI')\n",
    "ax.set_title('SPY 14-Day RSI')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_ylim(0, 100)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawdown: how far price has fallen from recent peak\n",
    "# Shows periods of sustained losses\n",
    "# Larger drawdowns = bigger losses, higher risk\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.fill_between(features_df['date'], 0, -features_df['drawdown_60d'] * 100, alpha=0.5, color='red')\n",
    "ax.plot(features_df['date'], -features_df['drawdown_60d'] * 100, linewidth=1, color='darkred')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Drawdown (%)')\n",
    "ax.set_title('SPY 60-Day Drawdown')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Max Drawdown: {features_df['drawdown_60d'].max() * 100:.2f}%\")\n",
    "print(f\"Mean Drawdown: {features_df['drawdown_60d'].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3a531",
   "metadata": {},
   "source": [
    "## 5. Cross-Asset Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdeb534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-asset correlations and spreads\n",
    "# SPY-TLT: stocks vs bonds (negative = flight to safety during crashes)\n",
    "# SPY-HYG: stocks vs high-yield bonds (positive = both risky assets move together)\n",
    "# HYG-TLT spread: credit risk premium (high-yield bonds outperforming treasuries)\n",
    "# RV-VIX spread: actual vs expected volatility (negative = VIX overpricing risk)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# SPY-TLT correlations\n",
    "axes[0, 0].plot(features_df['date'], features_df['corr_spy_tlt_20d'], label='20-day', linewidth=1)\n",
    "axes[0, 0].plot(features_df['date'], features_df['corr_spy_tlt_60d'], label='60-day', linewidth=1, alpha=0.7)\n",
    "axes[0, 0].axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "axes[0, 0].set_ylabel('Correlation')\n",
    "axes[0, 0].set_title('SPY-TLT Correlation')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# SPY-HYG correlations\n",
    "axes[0, 1].plot(features_df['date'], features_df['corr_spy_hyg_20d'], label='20-day', linewidth=1)\n",
    "axes[0, 1].plot(features_df['date'], features_df['corr_spy_hyg_60d'], label='60-day', linewidth=1, alpha=0.7)\n",
    "axes[0, 1].axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "axes[0, 1].set_ylabel('Correlation')\n",
    "axes[0, 1].set_title('SPY-HYG Correlation')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# HYG-TLT spread\n",
    "axes[1, 0].plot(features_df['date'], features_df['hyg_tlt_spread'], linewidth=0.8, alpha=0.7)\n",
    "axes[1, 0].axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Return Spread')\n",
    "axes[1, 0].set_title('HYG-TLT Daily Return Spread')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# RV-VIX spread\n",
    "axes[1, 1].plot(features_df['date'], features_df['rv_vix_spread_20d'], linewidth=0.8, alpha=0.7)\n",
    "axes[1, 1].axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Volatility Spread')\n",
    "axes[1, 1].set_title('Realized Vol (20d) - VIX Spread')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf27ac8",
   "metadata": {},
   "source": [
    "## 6. Feature Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f697db",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = features_df.describe().T\n",
    "summary['missing_count'] = features_df.isnull().sum()\n",
    "summary['missing_pct'] = (summary['missing_count'] / len(features_df) * 100).round(2)\n",
    "\n",
    "print(\"Feature Statistics Summary:\")\n",
    "print(summary[['count', 'mean', 'std', 'min', 'max', 'missing_count', 'missing_pct']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb718a5",
   "metadata": {},
   "source": [
    "## 7. Lookahead Bias Check\n",
    "\n",
    "Verify that features only use past data (no future information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cCheck that NaN patterns make sense for rolling windows\n",
    "print(\"Expected NaN patterns for rolling features:\\n\")\n",
    "\n",
    "windows = {\n",
    "    'spy_ret_5d': 5,\n",
    "    'spy_ret_10d': 10,\n",
    "    'spy_ret_20d': 20,\n",
    "    'spy_ret_60d': 60,\n",
    "    'spy_vol_5d': 5,\n",
    "    'spy_vol_10d': 10,\n",
    "    'spy_vol_20d': 20,\n",
    "    'spy_vol_60d': 60,\n",
    "    'drawdown_60d': 60,\n",
    "    'rsi_spy_14': 14,\n",
    "    'corr_spy_tlt_20d': 20,\n",
    "    'corr_spy_tlt_60d': 60\n",
    "}\n",
    "\n",
    "for feature, expected_nan in windows.items():\n",
    "    actual_nan = features_df[feature].isnull().sum()\n",
    "    first_valid_idx = features_df[feature].first_valid_index()\n",
    "    \n",
    "    print(f\"{feature:20s}: Expected ~{expected_nan:2d} NaNs, Got {actual_nan:3d}, First valid at row {first_valid_idx}\")\n",
    "\n",
    "print(\"\\n✅ All NaN patterns look correct. no lookahead bias detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa884c6",
   "metadata": {},
   "source": [
    "## 8. Correlation Matrix\n",
    "\n",
    "Check for multicollinearity among features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr matrix of all features\n",
    "corr_matrix = features_df.drop('date', axis=1).corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "ax.set_title('Feature Correlation Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#print high correlations (>0.9 or <-0.9)\n",
    "print(\"\\nHighly Correlated Features (|corr| > 0.9):\")\n",
    "high_corr = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "            high_corr.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "\n",
    "for feat1, feat2, corr in sorted(high_corr, key=lambda x: abs(x[2]), reverse=True):\n",
    "    print(f\"  {feat1:20s} <-> {feat2:20s}: {corr:6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564e56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
